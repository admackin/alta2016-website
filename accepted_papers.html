<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="logos/logo_sm.jpg">

    <title>ALTA 2016</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script src="http://www.w3schools.com/lib/w3data.js"></script>
  </head>

  <body>
    <div class="jumbotron">
      <div class="container">
        <br>
        <br>
        <h2>14th Annual Workshop of <br>The Australasian Language Technology Association</h2>
	<h3>Monash University, Melbourne</h3>
	<h3>5th - 7th December 2016</h3>
      </div>
    </div>
    
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Home</a>
          <a class="navbar-brand" href="accepted_papers.html">Programme</a>
          <a class="navbar-brand" href="attending.html">Attending</a>
          <a class="navbar-brand" href="tutorials.html">Tutorials</a>
          <a class="navbar-brand" href="http://alta.asn.au/events/sharedtask2016">Shared Task</a>
          <a class="navbar-brand" href="contacts.html">Organising Committee</a>
          <a class="navbar-brand" href="past_workshops.html">Past Workshops</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
        </div><!--/.navbar-collapse -->
      </div>
    </nav>

    <div class="container">
        <h2>Programme</h2>


<table class="table"><tbody>
<tr><td colspan="3"><h4>Monday 5th - Monash Caulfield B2.14</h4></td></tr>
<tr>
	<th scope="row">9:00</th>
	<td colspan="2">Tutorial 1a: NP Bayes</td>
</tr>
<tr>
	<th scope="row">10:15</th>
	<td colspan="2">Morning tea</td>
</tr>
<tr>
	<th scope="row">10:45</th>
	<td colspan="2">Tutorial 1b: NP Bayes</td>
</tr>
<tr>
	<th scope="row">12:15</th>
	<td colspan="2">Lunch</td>
</tr>
<tr>
	<th scope="row">13:30</th>
	<td colspan="2">Tutorial 2a: Succinct data struct.</td>
</tr>
<tr>
	<th scope="row">15:15</th>
	<td colspan="2">Afternoon tea</td>
</tr>
<tr>
	<th scope="row">15:45</th>
	<td colspan="2">Tutorial 2b: Succinct data struct.</td>
</tr>
<tr>
	<th scope="row">16:45</th>
	<td colspan="2">End of session</td>
</tr>
<tr><td colspan="3"><h4>Tuesday 6th - Monash Caulfield B2.14</h4></td></tr>
<tr>
	<td colspan="3">Session 1: Opening &amp; Invited talk</td>
</tr>
<tr>
	<th scope="row">9:00</th>
	<td colspan="2">Opening</td>
</tr>
<tr>
	<th scope="row">9:15</th>
	<td>Invited talk: Mark Steedman</td><td><a href="#steedman">On Distributional Semantics</a></td>
</tr>
<tr>
	<th scope="row">10:15</th>
	<td colspan="2">Morning tea</td>
</tr>
<tr>
	<td colspan="3">Session 2: Translation</td>
</tr>
<tr>
	<th scope="row">10:45</th>
	<td>Presentation: Kyo Kageura, Martin Thomas, Anthony Hartley, Masao Utiyama, Atsushi Fujita, Kikuko Tanabe and Chiho Toyoshima</td><td><i>Supporting Collaborative Translator Training: Online Platform, Scaffolding and NLP</i></td>
</tr>
<tr>
	<th scope="row">11:10</th>
	<td>Presentation : Nitika Mathur, Trevor Cohn and Timothy Baldwin</td><td><i>Improving Human Evaluation of Machine Translation</i></td>
</tr>
<tr>
	<th scope="row">11:25</th>
	<td>Paper: Cong Duy Vu Hoang, Reza Haffari and Trevor Cohn</td><td><i>Improving Neural Translation Models with Linguistic Factors</i></td>
</tr>
<tr>
	<th scope="row">11:40</th>
	<td>Presentation : Daniel Beck, Lucia Specia and Trevor Cohn</td><td><i>Exploring Prediction Uncertainty in Machine Translation Quality Estimation</i></td>
</tr>
<tr>
	<th scope="row">11:55</th>
	<td colspan="2">CLEF eHealth 2017 Shared tasks</td>
</tr>
<tr>
	<th scope="row">12:00</th>
	<td colspan="2">Lunch</td>
</tr>
<tr>
	<td colspan="3">Session 3a: Invited talk</td>
</tr>
<tr>
	<th scope="row">13:15</th>
	<td>Invited talk: Hercules Dalianis</td><td><a href="#dalianis">HEALTH BANK: A Workbench for Data Science Applications in Healthcare</a></td>
</tr>
<tr>
	<th scope="row">13:55</th>
	<td colspan="2">Break</td>
</tr>
<tr>
	<td colspan="3">Session 3b: Health</td>
</tr>
<tr>
	<th scope="row">14:00</th>
	<td>Presentation : Raghavendra Chalapathy, Ehsan Zare Borzeshi and Massimo Piccardi</td><td><i>An Investigation of Recurrent Neural Architectures for Drug Name Recognition</i></td>
</tr>
<tr>
	<th scope="row">14:15</th>
	<td>Paper: Hamed Hassanzadeh, Anthony Nguyen and Bevan Koopman</td><td><i>Evaluation of Medical Concept Annotation Systems on Clinical Records</i></td>
</tr>
<tr>
	<th scope="row">14:30</th>
	<td>Paper: Mahnoosh Kholghi, Lance De Vine, Laurianne Sitbon, Guido Zuccon and Anthony Nguyen</td><td><i>The Benefits of Word Embeddings Features for Active Learning in Clinical Information Extraction</i></td>
</tr>
<tr>
	<th scope="row">14:45</th>
	<td>Presentation : Rebecka Weegar and Hercules Dalianis</td><td><i>Mining Norwegian pathology reports: A research proposal</i></td>
</tr>
<tr>
	<th scope="row">15:00</th>
	<td>Paper: Pin Huang, Andrew MacKinlay and Antonio Jimeno</td><td><i>Syndromic Surveillance using Generic Medical Entities on Twitter</i></td>
</tr>
<tr>
	<th scope="row">15:15</th>
	<td>Paper: Yufei Wang, Stephen Wan and Cecile Paris</td><td><i>The Role of Features and Context on Suicide Ideation Detection</i></td>
</tr>
<tr>
	<th scope="row">15:30</th>
	<td colspan="2">Afternoon tea</td>
</tr>
<tr>
	<td colspan="3">Session 4: Relation &amp; Information extraction</td>
</tr>
<tr>
	<th scope="row">16:00</th>
	<td>Presentation : Dat Quoc Nguyen and Mark Johnson</td><td><i>Modeling topics and knowledge bases with embeddings</i></td>
</tr>
<tr>
	<th scope="row">16:15</th>
	<td>Paper: Zhuang Li, Lizhen Qu, Qiongkai Xu and Mark Johnson</td><td><i>Unsupervised Pre-training With Seq2Seq Reconstruction Loss for Deep Relation Extraction Models</i></td>
</tr>
<tr>
	<th scope="row">16:30</th>
	<td>Presentation : Hanieh Poostchi, Ehsan Zare Borzeshi and Massimo Piccardi</td><td><i>PersoNER: Persian Named-Entity Recognition</i></td>
</tr>
<tr>
	<th scope="row">16:45</th>
	<td>Paper: Nagesh C. Panyam, Karin Verspoor, Trevor Cohn and Rao Kotagiri</td><td><i>ASM Kernel: Graph Kernel using Approximate Subgraph Matching for Relation Extraction</i></td>
</tr>
<tr>
	<th scope="row">17:00</th>
	<td>Paper: Gitansh Khirbat, Jianzhong Qi and Rui Zhang</td><td><i>N-ary Biographical Relation Extraction using Shortest Path Dependencies</i></td>
</tr>
<tr>
	<th scope="row">17:15</th>
	<td colspan="2">End of session</td>
</tr>
<tr><td colspan="3"><h4>Wednesday 7th - Monash Caulfield B2.14</h4></td></tr>
<tr>
	<td colspan="3">Session 5: Invited talk &amp; Shared task</td>
</tr>
<tr>
	<th scope="row">9:00</th>
	<td>Invited talk: Steven Bird</td><td><a href="#bird">Getting started with an Australian language</a></td>
</tr>
<tr>
	<th scope="row">9:45</th>
	<td colspan="2">Shared Task</td>
</tr>
<tr><th></th><td>Andrew Chisholm, Ben Hachey and Diego Moll&aacute;</td><td><i>Overview of the 2016 ALTA Shared Task: Cross-KB Coreference</i></td></tr>
<tr><th></th><td>Gitansh Khirbat, Jianzhong Qi and Rui Zhang</td><td><i>Disambiguating Entities Referred by Web Endpoints using Tree Ensembles</i></td></tr>
<tr><th></th><td>S. Shivashankar, Yitong Li and Afshin Rahimi</td><td><i>Filter and Match Approach to Pair-wise Web URI Linking</i></td></tr>
<tr><th></th><td>Cheng Yu, Bing Chu, Rohit Ram, James Aichinger, Lizhen Qu and Hanna Suominen</td><td><i>Pairwise FastText Classifier for Entity Disambiguation</i></td></tr>
<tr>
	<th scope="row">10:15</th>
	<td colspan="2">Morning tea</td>
</tr>
<tr>
	<td colspan="3">Session 6: Short-papers &amp; posters</td>
</tr>
<tr>
	<th scope="row">10:45</th>
	<td colspan="2">Short-paper lightning talks</td>
</tr>
<tr><th></th><td>Aditya Joshi, Vaibhav Tripathi, Pushpak Bhattacharyya, Mark Carman, Meghna Singh, Jaya Saraswati and Rajita Shukla</td><td><i>How Challenging is Sarcasm versus Irony Classification?: A Study With a Dataset from English Literature</i></td></tr>
<tr><th></th><td>Ming Liu, Gholamreza Haffari and Wray Buntine</td><td><i>Learning cascaded latent variable models for biomedical text classification</i></td></tr>
<tr><th></th><td>Bo Han, Antonio Jimeno Yepes, Andrew MacKinlay and Lianhua Chi</td><td><i>Temporal Modelling of Geospatial Words in Twitter</i></td></tr>
<tr><th></th><td>Antonio Jimeno Yepes and Andrew MacKinlay</td><td><i>NER for Medical Entities in Twitter using Sequence to Sequence Neural Networks</i></td></tr>
<tr><th></th><td>Dat Quoc Nguyen, Mark Dras and Mark Johnson</td><td><i>An empirical study for Vietnamese dependency parsing</i></td></tr>
<tr><th></th><td>Will Radford, Ben Hachey, Bo Han and Andy Chisholm</td><td><i>:telephone::person::sailboat::whale::okhand: ; or “Call me Ishmael” – How do you translate emoji?</i></td></tr>
<tr><th></th><td>Xavier Holt, Will Radford and Ben Hachey</td><td><i>Presenting a New Dataset for the Timeline Generation Problem</i></td></tr>
<tr>
	<th scope="row">11:10</th>
	<td colspan="2">Poster Session</td>
</tr>
<tr>
	<th scope="row">12:00</th>
	<td colspan="2">Lunch</td>
</tr>
<tr>
	<th scope="row">13:15</th>
	<td colspan="2">Business Meeting </td>
</tr>
<tr>
	<td colspan="3">Session 7: Applications</td>
</tr>
<tr>
	<th scope="row">13:35</th>
	<td>Paper: Hafsah Aamer, Bahadorreza Ofoghi and Karin Verspoor</td><td><i>Syndromic Surveillance through Measuring Lexical Shift in Emergency Department Chief Complaint Texts</i></td>
</tr>
<tr>
	<th scope="row">13:50</th>
	<td>Paper: Rui Wang, Wei Liu and Chris McDonald</td><td><i>Featureless Domain-Specific Term Extraction with Minimal Labelled Data</i></td>
</tr>
<tr>
	<th scope="row">14:05</th>
	<td>Presentation : Ehsan Shareghi</td><td><i>Unbounded and Scalable Smoothing for Language Modeling</i></td>
</tr>
<tr>
	<th scope="row">14:30</th>
	<td>Paper: Shunichi Ishihara</td><td><i>An Effect of Background Population Sample Size on the Performance of a Likelihood Ratio-based Forensic Text Comparison System: A Monte Carlo Simulation with Gaussian Mixture Model</i></td>
</tr>
<tr>
	<th scope="row">14:45</th>
	<td>Presentation: Oliver Adams, Shourya Roy and Raghu Krishnapuram</td><td><i>Distributed Vector Representations for Unsupervised Automatic Short Answer Grading</i></td>
</tr>
<tr>
	<th scope="row">15:00</th>
	<td>Paper: Andrei Shcherbakov, Ekaterina Vylomova and Nick Thieberger</td><td><i>Phonotactic Modeling of Extremely Low Resource Languages</i></td>
</tr>
<tr>
	<th scope="row">15:15</th>
	<td>Paper: Oliver Adams, Adam Makarucha, Graham Neubig, Steven Bird and Trevor Cohn</td><td><i>Cross-Lingual Word Embeddings for Low-Resource Language Modeling</i></td>
</tr>
<tr>
	<th scope="row">15:30</th>
	<td colspan="2">Afternoon tea</td>
</tr>
<tr>
	<td colspan="3">Session 8: Closing</td>
</tr>
<tr>
	<th scope="row">16:20</th>
	<td colspan="2">Awards for best paper and best presentation</td>
</tr>
<tr>
	<th scope="row">16:30</th>
	<td colspan="2">ALTA Closing</td>
</tr>
<tr>
	<th scope="row">16:45</th>
	<td colspan="2">End of session</td>
</tr>
</tbody></table>


<h3 id="invited">Invited talks</h3>

<h4 id="steedman">Mark Steedman (University of Edinburgh)</h4>
<i>On Distributional Semantics</i>

<p>
The central problem in open domain-question answering from text is the
problem of entailment.  Given enough text, the answer is almost
certain to be there, but is likely to be expressed in a different form
from the one the question suggest-either in a paraphrase, or in a
sentence that entails or implies the answer.

<p>
We cannot afford to bridge this gap by open-ended theorem-proving
search.  Instead we need a semantics for natural language that
directly supports common-sense inference, such as that <i>arriving
somewhere</i> implies subsequently <i>being there</i>, and <i>invading</i> a
country implies <i>attacking</i> it.  We would like this semantics to be
compatible with traditional logical operator semantics including
quantification, negation and tense, so that <i>not being there</i> implies
<i>not having arrived</i>, and <i>not attacking</i> implies <i>not invading</i>.

<p>
There have been many attempts to build such a semantics of content
words by hand, from the generative semantics of the '60s to
WordNet and other resources of the present.  The '60s saw attempts
based on generative semantics, while more recently, they have
engendered WordNet and other computational resources.  However, such
systems have remained incomplete and language-specific in comparison to
the vastness of human common-sense reasoning. One consequence has been
renewed interest in the idea of treating the semantics as &quot;hidden&quot;, to
be discovered through machine learning, an idea that has its origins
in the &quot;semantic differential&quot; of Osgood, Suci, and Tannenbaum in the
'50s.

<p>
There are two distinct modern approaches to the problem of data-driven
or &quot;distributional&quot; semantics.  The first, which I will call
&quot;collocational&quot;, is the direct descendant of the semantic
differential. In its most basic form, the meaning of a word is taken
to be a vector in a space whose dimensions are defined by the lexicon
of the language, and whose magnitude is defined by counts of those
lexical items within a fixed window over the string (although in
practice the dimensionality is reduced and the relation to frequency
less direct).  Crucially, semantic composition is defined in terms of
linear algebraic operations, notably vector addition.

<p>
A second &quot;denotational&quot; approach defines the meaning of a word in
terms of the entities that it is predicated over and the ensembles of
predications over entities of the same types, obtained by
machine-reading with wide coverage parsers.  (Names or designators in
text are generally used as a proxy for the entities themselves.)
Semantic composition can then be defined as an applicative system
using logical opertors such as quantifiers and negation, as in
traditional formal semantics.

<p>
The talk reviews recent work in both collocation- and denotation-
based distributional semantics, and asks for each what dimensions of
meaning are actually being represented.  It argues that the two
approaches are largely orthogonal on these dimensions.  Collocational
representations are good for representing ambiguity, with linear
algebraic composition most effective at disambiguation and
representing distributional similarity.  Denotational representations
represent something more like a traditional compositional semantics,
but one in which the primitive relations correspond to those of a
hidden language of logical form representing paraphrase and
common-sense entailment directly.

<p>
To make this point, the talk discusses recent work in which
collocational distributional representations such as embeddings have
been used as proxies for semantic features in models such as LSTM, to
guide disambiguation during parsing, while a lexicalized
denotation-based distributional semantics is used to support inference
of entailment.  I will show that this hybrid approach can be applied
with a number of parsing models, including transition-based and
supertagging, to support entailment-based QA with denotation-based
distributional representations.  I will discuss work at Edinburgh and
elsewhere in which the semantics of paraphrases is represented by a
single cluster identifier, and where common-sense inference (derived
from a learned entailment graph) is built into the lexicon and
projected by syntactic derivation, rather than delegated to a later
stage of inference. The method can be applied cross-linguistically, in
support of machine translation.  Ongoing work extends the method to
extract multi-word items, light-verb constructions, and an
aspect-based semantics for temporal/causal entailment, and to the
creation and interrogation of Knowledge Graphs and Semantic Nets via
natural language.

<h4 id="dalainis">Hercules Dalianis (Stockholm University)</h4>
<i>HEALTH BANK: A Workbench for Data Science Applications in Healthcare</i>

<p>
Healthcare has many challenges in form of monitoring and predicting
adverse events as healthcare associated infections or adverse drug
events.  All this can happen while treating a patient at the hospital
for her disease. The research question is: When and how many adverse
events have occurred, how can one predict them? Nowadays all information
is contained in the electronic patient records and are written both in
structured form and in unstructured free text.  This talk will describe
the data used for our research in HEALTH BANK - Swedish Health Record
Research Bank containing over 2 million patient records from 2007-2014.
Topics are detection of symptoms, diseases, body parts and drugs from
Swedish electronic patient record text, including deciding on the
certainty of a symptom or disease and detecting adverse (drug) events.
Future research are detecting early symptoms of cancer and
de-identification of electronic patient records for secondary use.


<h4 id="bird">Steven Bird (University of Melbourne, University of California Berkeley)</h4>
<i>Getting started with an Australian language</i>

<p>
At least a dozen Australian indigenous languages are still being learnt by children as their first language. These children have limited access to
western-style education and often gain only limited proficiency in English. The languages are effectively unwritten, as there are no naturally
occurring  contexts where people would need to write the language. The same situation is repeated around the world, where remote communities do
not write their      language and do not acquire the
national language, and government and NGO employees who work with these communities must learn to speak an unwritten language without the help of
written resources. In this presentation I will report on early experiences working with Kunwinjku, a polysynthetic language spoken by 1,200 people
in western     Arnhem Land, leading to several open research questions in the area of tools for adult learners of unwritten languages.




    
      <footer class="attrib-footer">
        <p>&copy; ALTA 2016 | The banner image of Monash University was adapted from <a href="https://commons.wikimedia.org/wiki/File:MonashUni-Caulfield-ServiceCentre.jpg">a photo by user Natebailey on Wikipedia</a> and is used under the <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">Creative Commons 3.0 Unported Licence</a></p>
      </footer>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script src="../../dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
